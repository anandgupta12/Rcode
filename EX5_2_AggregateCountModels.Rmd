---
title: "Analysis of Aggregate Count Data"
author: "coreysparks"
date: "February 23, 2015"
output: 
  html_document:
    fig_height: 7
    fig_width: 8
---

This example continues the coverage of the use of count data models. Instead of using individual survey data, in this example, I use truly aggregate counts. The data consist of county-level counts of deaths and population totals for US counties between the years 1999-2010. These data come from the CDC Wonder Compressed Mortality File Public Use Data [Link](http://wonder.cdc.gov/controller/datarequest/D105). 

```{r load}
setwd("~/Google Drive//dem7263/data")
library(spdep)
library(maptools)
library(car)
library(lmtest)
library(aod)
library(RColorBrewer)
library(MASS)
dat<-readShapePoly("usdata_mort.shp")

```

```{r recodes}
dat$deaths<-as.numeric(as.character(dat$Deaths))
dat$population<-as.numeric(as.character(dat$Population))
dat$mortrate<-1000*(dat$deaths/dat$poptot)
spplot(dat, "mortrate", at=quantile(dat$mortrate[is.finite(dat$mortrate)]), col.regions=brewer.pal(n = 6, name = "Blues"))
dat$offset<-dat$poptot+1


```

###Binomial and Poisson models
Here are the basic Binomial (y,n) model and the basic Poisson models. The correction of the p-values in the Poisson model comes from Prof. German RodrÄ±guez's notes [Link](http://data.princeton.edu/wws509/notes/c4a.pdf). 

```{r mods1}

#for the poisson I make an expected value, E_i = r* n_i, r = sum y_i / sum n_i
dat$E<-dat$poptot*(sum(dat$deaths)/sum(dat$poptot))
fit.blm<-glm(cbind(deaths, population)~pblack_1+phisp+ppersonspo+ppopmarrie+DISSWB, data=dat, family=binomial)
fit.plm<-glm(deaths~offset(log(population))+pblack_1+phisp+ppersonspo+ppopmarrie+DISSWB, data=dat@data, family=poisson)
summary(fit.blm)
summary(fit.plm)

#This should be 1 if the poisson model fits ok. This should equal 1.
fit.plm$deviance/fit.plm$df.residual
#it's not 1

#correct the se's by hand using the deviance x^2 / residual df
phi<-fit.plm$deviance/(length(dat$deaths)-length(coef(fit.plm)))
sumsp<-summary(fit.plm)$coef
newt<-sumsp[,1]/(sumsp[,2]*sqrt(phi))
newp<-2 * pnorm(-abs(newt))
data.frame(oldt=sumsp[,3],newt=newt, oldp=sumsp[,4],newp=round(newp,5))


```

Which doesn't look like much, but all of the original p-values for the Poisson model assuming no overdispersion were all <2e-16, or 0.

###Other Count models
Here are the Negative Binomial and Beta-Binomial models. The NB model is in the `MASS` library and the Beta-binomial is in `aod`.

```{r mods2}
fit.nblm<-glm.nb(deaths~offset(log(population))+pblack_1+phisp+ppersonspo+ppopmarrie+DISSWB, data=dat@data)
summary(fit.nblm)

fit.bblm<-betabin(cbind(deaths, population)~pblack_1+phisp+ppersonspo+ppopmarrie+DISSWB,random=~1, data=dat@data)
summary(fit.bblm)

```

Examine the AICs of each model:
```{r aics}

stats::AIC(fit.blm)
stats::AIC(fit.plm)
stats::AIC(fit.nblm)
AIC(fit.bblm)@istats$AIC

```

The beta-binomial model appears to fit the data best, with and AIC of `r round(AIC(fit.bblm)@istats$AIC, 2)`. 

Map the fitted rates
```{r fitted plot}
dat$fitted<-1000*predict(fit.bblm)
plot(mortrate~fitted, dat)
spplot(dat, "fitted", at=quantile(dat$fitted), col.regions=brewer.pal(n = 6, name = "Blues"), main="Fitted Rates")


```
